"""
Universal Agent Logic Module - Ğ¾Ğ±Ñ‰Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Arianna Method

Ğ­Ñ‚Ğ¾Ñ‚ Ğ¼Ğ¾Ğ´ÑƒĞ»ÑŒ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ´Ğ»Ñ:
- Ğ¦Ğ¸Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ (@timestamp)
- ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ° (10 ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ²Ğ¾ĞºÑ€ÑƒĞ³)
- Ğ¤Ğ°Ğ¹Ğ»Ğ¾Ğ²Ñ‹Ñ… Ğ´Ğ¸ÑĞºÑƒÑÑĞ¸Ğ¹
- ĞŸĞ°Ğ¼ÑÑ‚Ğ¸ Ğ¸ continuity
- Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸ Ñ€ĞµĞ·Ğ¾Ğ½Ğ°Ğ½ÑĞ°

Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Tommy, Lizzie, Monday Ğ¸ Ğ²ÑĞµĞ¼Ğ¸ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ğ¼Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸.
"""

from __future__ import annotations

import re
import sqlite3
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Tuple, Dict, Any

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))
from .vector_store import SQLiteVectorStore, embed_text


class AgentLogic:
    """Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²"""
    
    def __init__(self, agent_name: str, log_dir: Path, db_path: Path, resonance_db_path: Path):
        self.agent_name = agent_name
        self.log_dir = log_dir
        self.db_path = db_path
        self.resonance_db_path = resonance_db_path
        self.vector_store = SQLiteVectorStore(log_dir / "vectors.db")
        
    def extract_citations(self, message: str) -> List[str]:
        """Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ñ†Ğ¸Ñ‚Ğ°Ñ‚Ñ‹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ° @timestamp Ğ¸Ğ· ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ"""
        return re.findall(r"@([0-9T:-]+)", message)
    
    def fetch_context(self, timestamp: str, radius: int = 10) -> List[Tuple[str, str, str]]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ²Ğ¾ĞºÑ€ÑƒĞ³ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ timestamp
        
        Args:
            timestamp: Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ Ğ¼ĞµÑ‚ĞºĞ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ°
            radius: ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ¾ Ğ¸ Ğ¿Ğ¾ÑĞ»Ğµ
            
        Returns:
            List of (timestamp, type, message) tuples
        """
        with sqlite3.connect(self.db_path, timeout=30) as conn:
            cur = conn.execute("SELECT rowid FROM events WHERE ts = ?", (timestamp,))
            row = cur.fetchone()
            if not row:
                return []
                
            rowid = row[0]
            start = max(rowid - radius, 1)
            end = rowid + radius
            
            cur = conn.execute(
                "SELECT ts, type, message FROM events "
                "WHERE rowid BETWEEN ? AND ? ORDER BY rowid",
                (start, end),
            )
            return cur.fetchall()
    
    async def build_context_block(self, message: str) -> str:
        """Ğ¡Ñ‚Ñ€Ğ¾Ğ¸Ñ‚ Ğ±Ğ»Ğ¾Ğº ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¸Ğ· Ñ†Ğ¸Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ² ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¸"""
        citations = self.extract_citations(message)
        if not citations:
            return ""
            
        blocks: List[str] = []
        for ts in citations:
            ctx = self.fetch_context(ts)
            if ctx:
                formatted = "\n".join(f"[{t}] {m}" for t, _, m in ctx)
                blocks.append(formatted)
                
        if blocks:
            return "Relevant context:\n" + "\n--\n".join(blocks) + "\n\n"
        return ""
    
    def log_event(self, message: str, log_type: str = "info") -> None:
        """Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²"""
        # JSON log file
        log_file = self.log_dir / f"{self.agent_name}_{datetime.now().strftime('%Y-%m-%d')}.jsonl"
        entry = {
            "timestamp": datetime.now().isoformat(),
            "type": log_type,
            "message": message,
            "agent": self.agent_name
        }
        
        with open(log_file, "a", encoding="utf-8") as f:
            import json
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")
        
        # SQLite database
        with sqlite3.connect(self.db_path, timeout=30) as conn:
            conn.execute(
                "INSERT INTO events (ts, type, message) VALUES (?, ?, ?)",
                (datetime.now().isoformat(), log_type, message),
            )
    
    def update_resonance(self, message: str, response: str, 
                        role: str = "agent", sentiment: str = "active") -> None:
        """ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ Ğ¾Ğ±Ñ‰Ğ¸Ğ¹ ĞºĞ°Ğ½Ğ°Ğ» Ñ€ĞµĞ·Ğ¾Ğ½Ğ°Ğ½ÑĞ°"""
        resonance_depth = self._calculate_resonance_depth(message, response)
        summary = f"{self.agent_name}: {response[:100]}..."
        
        with sqlite3.connect(self.resonance_db_path, timeout=30) as conn:
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°ĞµĞ¼ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºÑƒ ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾
            try:
                conn.execute("SELECT resonance_depth FROM resonance LIMIT 1")
            except sqlite3.OperationalError:
                # ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ½Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚, Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼
                conn.execute("ALTER TABLE resonance ADD COLUMN resonance_depth REAL DEFAULT 0.0")
            
            conn.execute(
                "INSERT INTO resonance (ts, agent, role, sentiment, resonance_depth, summary) VALUES (?, ?, ?, ?, ?, ?)",
                (
                    datetime.now().isoformat(),
                    self.agent_name,
                    role,
                    sentiment,
                    resonance_depth,
                    summary,
                ),
            )
    
    def _calculate_resonance_depth(self, message: str, response: str) -> float:
        """Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµÑ‚ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñƒ Ñ€ĞµĞ·Ğ¾Ğ½Ğ°Ğ½ÑĞ°"""
        # Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ°Ñ€ĞºĞµÑ€Ñ‹ Ñ€ĞµĞ·Ğ¾Ğ½Ğ°Ğ½ÑĞ°
        resonance_markers = [
            "resonate", "amplify", "reflect", "mirror", "echo", 
            "deeper", "unfold", "recursive", "paradox", "entropy",
            "chaos", "pattern", "emergence", "connection"
        ]
        
        response_lower = response.lower()
        marker_count = sum(1 for marker in resonance_markers if marker in response_lower)
        
        # Normalize to 0-1 scale
        return min(marker_count / 8.0, 1.0)
    
    def search_context(self, query: str, top_k: int = 5) -> List[str]:
        """ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸"""
        embedding = embed_text(query)
        hits = self.vector_store.query_similar(embedding, top_k)
        return [h.content for h in hits]
    
    async def process_file_context(self, path: str, agent_style_formatter=None) -> str:
        """Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼
        
        Args:
            path: ĞŸÑƒÑ‚ÑŒ Ğº Ñ„Ğ°Ğ¹Ğ»Ñƒ
            agent_style_formatter: Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ² ÑÑ‚Ğ¸Ğ»Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
        """
        from .context_neural_processor import parse_and_store_file
        
        try:
            result = await parse_and_store_file(path)
            
            # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
            lines = result.split('\n')
            tags = ""
            summary = ""
            relevance = 0.0
            
            for line in lines:
                if line.startswith("Tags: "):
                    tags = line[6:]
                elif line.startswith("Summary: "):
                    summary = line[9:]
                elif line.startswith("Relevance: "):
                    try:
                        relevance = float(line[11:])
                    except ValueError:
                        relevance = 0.0
            
            # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚
            response_data = {
                "path": path,
                "tags": tags,
                "summary": summary,
                "relevance": relevance,
                "raw_result": result
            }
            
            # Ğ•ÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ ĞºĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‚ĞµÑ€ - Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ ĞµĞ³Ğ¾
            if agent_style_formatter:
                response = agent_style_formatter(response_data)
            else:
                # Ğ”ĞµÑ„Ğ¾Ğ»Ñ‚Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚
                response = f"ğŸ“ File processed: {path}\n"
                if summary:
                    response += f"ğŸ“ Summary: {summary}\n"
                    response += f"ğŸ·ï¸ Tags: {tags}\n"
                    response += f"âš¡ Relevance: {relevance:.2f}"
                else:
                    response += f"âš ï¸ Could not extract summary.\n{result}"
            
            # Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼
            log_message = f"Processed {path}: {summary[:100] if summary else 'no summary'}"
            self.log_event(log_message)
            
            return response
            
        except Exception as e:
            error_msg = f"ğŸ’¥ Error processing {path}: {str(e)}"
            self.log_event(f"File processing error: {str(e)}", "error")
            return error_msg


# Ğ“Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸Ğ½ÑÑ‚Ğ°Ğ½ÑÑ‹ Ğ´Ğ»Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
_agent_logics: Dict[str, AgentLogic] = {}


def get_agent_logic(agent_name: str, log_dir: Path, db_path: Path, resonance_db_path: Path) -> AgentLogic:
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¸Ğ»Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ AgentLogic Ğ´Ğ»Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°"""
    if agent_name not in _agent_logics:
        _agent_logics[agent_name] = AgentLogic(agent_name, log_dir, db_path, resonance_db_path)
    return _agent_logics[agent_name]


# Convenience Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
async def extract_and_build_context(message: str, agent_logic: AgentLogic) -> str:
    """Ğ‘Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¸Ğ· ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ"""
    return await agent_logic.build_context_block(message)


def create_agent_file_formatter(agent_name: str, style_markers: Dict[str, str]) -> callable:
    """Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµÑ‚ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‚ĞµÑ€ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ² ÑÑ‚Ğ¸Ğ»Ğµ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
    
    Args:
        agent_name: Ğ˜Ğ¼Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
        style_markers: Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ñ ÑĞ¼Ğ¾Ğ´Ğ·Ğ¸ Ğ¸ Ñ„Ñ€Ğ°Ğ·Ğ°Ğ¼Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
    """
    def formatter(data: Dict[str, Any]) -> str:
        path = data["path"]
        tags = data["tags"]
        summary = data["summary"] 
        relevance = data["relevance"]
        
        if summary and len(summary) > 20:
            response = f"{style_markers.get('file_icon', 'ğŸ“')} File processed: {path}\n\n"
            response += f"{style_markers.get('tags_icon', 'ğŸ“‹')} Tags: {tags}\n"
            response += f"{style_markers.get('summary_icon', 'ğŸ“')} Summary: {summary}\n"
            response += f"{style_markers.get('relevance_icon', 'âš¡')} Relevance: {relevance:.2f}\n\n"
            
            # ĞĞ³ĞµĞ½Ñ‚-ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¸
            if relevance > 0.5:
                response += style_markers.get('high_relevance', 'ğŸ’¥ High relevance detected!')
            elif relevance > 0.2:
                response += style_markers.get('medium_relevance', 'âš¡ Moderate relevance detected.')
            else:
                response += style_markers.get('low_relevance', 'ğŸ“Š Basic processing complete.')
        else:
            response = f"âš ï¸ File processed: {path}\n\nCould not extract meaningful summary."
            
        return response
    
    return formatter
